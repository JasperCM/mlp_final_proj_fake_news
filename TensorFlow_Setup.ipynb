{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jaspermeijering/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "TensorFlow version: 1.7.0\n",
      "Eager execution: False\n"
     ]
    }
   ],
   "source": [
    "# based on this guide: https://www.tensorflow.org/get_started/eager\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "#tf.enable_eager_execution() # must be run on a start up program\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>day</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>hour</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>7.092405</td>\n",
       "      <td>21</td>\n",
       "      <td>236.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>8.394500</td>\n",
       "      <td>14</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6.729679</td>\n",
       "      <td>16</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186418</td>\n",
       "      <td>20</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.425915</td>\n",
       "      <td>14</td>\n",
       "      <td>129.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth  category  day  depth  engangement  hour  nfollowees  nfollowers  \\\n",
       "0        1  Politics   22      0     7.092405    21       236.0       164.0   \n",
       "1        1  Politics   23      0     8.394500    14      1999.0       870.0   \n",
       "2        1  Politics    9      0     6.729679    16      1982.0       452.0   \n",
       "3        1  Politics   15      0     0.186418    20        55.0         5.0   \n",
       "4        1  Politics   14      0     1.425915    14       129.0        95.0   \n",
       "\n",
       "   size veracity verified  virality  \n",
       "0     1    FALSE    False       NaN  \n",
       "1     1    FALSE    False       NaN  \n",
       "2     1    FALSE    False       NaN  \n",
       "3     1    FALSE    False       NaN  \n",
       "4     1    FALSE    False       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load in the data\n",
    "\n",
    "metadata_file = '/Users/jaspermeijering/Google Drive/a Study/EPA Study Abroad - Carnegie Mellon University/Courses/CMU - 95845 - Applied Analytics The Machine Learning Pipeline/Machine Learning Pipeline Final Project/Data/FalseNews_Code_Data/data/metadata_anon.txt'\n",
    "\n",
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]\n",
    "\n",
    "    # Get static measures\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "day = []\n",
    "hour = []\n",
    "\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    veracity.append(metadata['veracity'])\n",
    "    virality.append(metadata['virality'])\n",
    "    depth.append(metadata['depth'])\n",
    "    breadth.append(metadata['max_breadth'])\n",
    "    size.append(metadata['size'])\n",
    "    verified.append(metadata['verified_list'][0])\n",
    "    nfollowers.append(metadata['num_followers_list'][0])\n",
    "    nfollowees.append(metadata['num_followees_list'][0])\n",
    "    engagement.append(metadata['engagement_list'][0])\n",
    "    category.append(metadata['rumor_category'])\n",
    "    day.append(metadata['start_date'].day)\n",
    "    hour.append(metadata['start_date'].hour)\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({'veracity': veracity, 'virality': virality, 'depth': depth, 'breadth': breadth, 'size': size, 'verified': verified, 'nfollowers': nfollowers, \n",
    "                   'nfollowees': nfollowees, 'engangement': engagement, 'category': category, 'day': day, 'hour': hour})\n",
    "\n",
    "# Inspect\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "#def parse_data(line):\n",
    " #   example_defaults = [[0.], [0.], [0.], [0.], [0]]  # sets field types\n",
    "  #features = tf.reshape(parsed_line[:-1], shape=(4,))\n",
    "   # # Last field is the label\n",
    "  #  label = tf.reshape(parsed_line[-1], shape=())\n",
    "  #  return features, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_saved = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed categories to numeric values, this is how they match [Politics, Viral Photos/Stories/Urban Legends, War/Terrorism/Shootings, Science/Nature/Tech/Food/Health, Entertainment, Business, Natural Disasters]\n",
      "Categories (7, object): [Politics, Viral Photos/Stories/Urban Legends, War/Terrorism/Shootings, Science/Nature/Tech/Food/Health, Entertainment, Business, Natural Disasters] [4 6 7 5 2 1 3]\n",
      "Transformed veracity to numeric values, this is how they match [FALSE, TRUE, MIXED]\n",
      "Categories (3, object): [FALSE, TRUE, MIXED] [1 3 2]\n",
      "Index(['True', 'False', 'None'], dtype='object')\n",
      "Transformed verified to numeric values, this is how they match ['None'] [3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category_num</th>\n",
       "      <th>day</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>hour</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity_num</th>\n",
       "      <th>verified_num</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>7.092405</td>\n",
       "      <td>21</td>\n",
       "      <td>236.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>8.394500</td>\n",
       "      <td>14</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6.729679</td>\n",
       "      <td>16</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186418</td>\n",
       "      <td>20</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.425915</td>\n",
       "      <td>14</td>\n",
       "      <td>129.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth  category_num  day  depth  engangement  hour  nfollowees  \\\n",
       "0        1             4   22      0     7.092405    21       236.0   \n",
       "1        1             4   23      0     8.394500    14      1999.0   \n",
       "2        1             4    9      0     6.729679    16      1982.0   \n",
       "3        1             4   15      0     0.186418    20        55.0   \n",
       "4        1             4   14      0     1.425915    14       129.0   \n",
       "\n",
       "   nfollowers  size  veracity_num  verified_num  virality  \n",
       "0       164.0     1             1             3       NaN  \n",
       "1       870.0     1             1             3       NaN  \n",
       "2       452.0     1             1             3       NaN  \n",
       "3         5.0     1             1             3       NaN  \n",
       "4        95.0     1             1             3       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make category numeric\n",
    "df[\"category\"] = df[\"category\"].astype('category')\n",
    "df[\"category_num\"] = df.category.cat.rename_categories([1,2,3,4,5,6,7])\n",
    "df[\"category_num\"] = df[\"category_num\"].astype('int')\n",
    "print(\"Transformed categories to numeric values, this is how they match\",df.category.unique(),df.category_num.unique())\n",
    "\n",
    "# Make veracity numeric\n",
    "df[\"veracity\"] = df[\"veracity\"].astype('category')\n",
    "df[\"veracity_num\"] = df.veracity.cat.rename_categories([1,2,3])\n",
    "df[\"veracity_num\"] = df[\"veracity_num\"].astype('int')\n",
    "print(\"Transformed veracity to numeric values, this is how they match\",df.veracity.unique(),df.veracity_num.unique())\n",
    "\n",
    "# Make verified numeric\n",
    "df[\"verified_cat\"] = df[\"verified\"].astype('category')\n",
    "df[\"verified_cat\"] = df[\"verified_cat\"].cat.set_categories([\"True\",\"False\",\"None\"])\n",
    "#df[\"verified_cat\"].isnull().sum() # 136 nan / none values for verified\n",
    "df.loc[df[\"verified_cat\"].isnull(),'verified'] = \"None\" # -> leave these cascades in. \n",
    "df[\"verified_num\"] = df.verified_cat.cat.rename_categories([1,2,3])\n",
    "df[\"verified_num\"] = df[\"verified_num\"].astype('int')\n",
    "print(\"Transformed verified to numeric values, this is how they match\",df.verified.unique(),df.verified_num.unique())\n",
    "\n",
    "# Only keep relevant columns\n",
    "column_names_df = ['breadth', 'category_num', 'day', 'depth', 'engangement', 'hour','nfollowees', 'nfollowers', 'size', 'veracity_num', 'verified_num', 'virality']\n",
    "df = df.loc[:,column_names_df]\n",
    "#df.dtypes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop Nan values for virality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_x = df[[\"breadth\",\"category\",\"day\",\"depth\",\"engangement\",\"hour\",\"nfollowees\",\"nfollowers\",\"size\",\"veracity\",\"verified\"]]\n",
    "df_x = df[[\"breadth\",\"day\",\"category\",\"depth\",\"engangement\",\"hour\",\"nfollowees\",\"nfollowers\",\"size\",\"verified\"]]\n",
    "df_y = df[['veracity']] \n",
    "df_x.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model with non numerical columns does not work therefore (for now) only take the numerical variables (and use day as the y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x_test = df[[\"breadth\",\"depth\",\"engangement\",\"hour\",\"nfollowees\",\"nfollowers\",\"size\"]]\n",
    "df_y_test = df[['day']]  #does not work in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.head(10) # does not work in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_x[\"category\"] = df_x[\"category\"].astype('category')\n",
    "#df_y.loc[:,1] = df_y[\"veracity\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_x[\"category\"] = df_x[\"category\"].astype('category')\n",
    "df_x  = df_x.as_matrix()\n",
    "df_y = df_y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=7))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = df_x_test\n",
    "labels = df_y_test\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(df_x_test, df_y_test, batch_size=128) # first split train and test set (code is elsewhere)\n",
    "#loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM for sequence classification\n",
    "In this model, we stack 3 LSTM layers on top of each other, making the model capable of learning higher-level temporal representations.\n",
    "\n",
    "The first two LSTMs return their full output sequences, but the last one only returns the last step in its output sequence, thus dropping the temporal dimension (i.e. converting the input sequence into a single vector).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
